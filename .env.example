# API Keys (Optional - use whichever you have access to)
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
GEMINI_API_KEY=your_gemini_api_key

# Local Models (Ollama - running on HOST system)
# Install on host: curl -fsSL https://ollama.com/install.sh | sh
# Then: ollama pull llama3.2 && ollama pull nomic-embed-text
# For local development (Python running on host): use localhost
# For Docker deployment: use http://host.docker.internal:11434
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL_EMBEDDING=nomic-embed-text
OLLAMA_MODEL_CLASSIFICATION=qwen3:latest
OLLAMA_MODEL_EXTRACTION=qwen3:latest

# Social Media APIs (No Twitter API needed - uses Playwright scraping)
REDDIT_CLIENT_ID=your_reddit_client_id
REDDIT_CLIENT_SECRET=your_reddit_client_secret
REDDIT_USER_AGENT=KnowInfo/1.0

TELEGRAM_BOT_TOKEN=your_telegram_bot_token

# Messaging Bots (ALL FREE!)
# Telegram (RECOMMENDED - FREE, official API, rich features)
TELEGRAM_BOT_TOKEN=your_telegram_bot_token

# WhatsApp (PyWhatKit - FREE but requires GUI, not for production)
# No config needed - uses WhatsApp Web

# Database
# For local development (Python on host, databases in Docker): use localhost
# For full Docker deployment: use service names (mongodb, neo4j, redis)
MONGODB_URI=mongodb://localhost:27017
MONGODB_DB_NAME=knowinfo

NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=knowinfo_password

REDIS_URL=redis://localhost:6379/0

# NotebookLM / RAG Configuration
VECTOR_DB_PATH=./data/vector_db
KNOWLEDGE_BASE_PATH=./data/knowledge_base

# External Services
GOOGLE_CUSTOM_SEARCH_API_KEY=your_google_api_key
GOOGLE_CUSTOM_SEARCH_ENGINE_ID=your_search_engine_id

# Application Settings
ENVIRONMENT=development
LOG_LEVEL=INFO
API_PORT=8000

# Rate Limiting
MAX_REQUESTS_PER_HOUR_FREE=1000
MAX_REQUESTS_PER_HOUR_ENTERPRISE=unlimited

# Detection Thresholds
VELOCITY_SPIKE_THRESHOLD=500
SIMILARITY_THRESHOLD=0.85
CONFIDENCE_THRESHOLD_LOW=60
CONFIDENCE_THRESHOLD_HIGH=80
